{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building up a Neural Network\n",
    "\n",
    "Now that we have seen logitic regression in action we shall now show how the accuracy on the test set can be significantly improved with the introdiction of more nodes.\n",
    "\n",
    "In this way, one can view a neural network as multiple applications of a logistic regression algorithm that is better able to capture the nonlinear features in the data.\n",
    "\n",
    "Before getting started let's define the notation:\n",
    "\n",
    "- Superscript $[l]$ denotes a quantity associated with the $l^{th}$ layer. \n",
    "    - Example: $a^{[L]}$ is the $L^{th}$ layer activation. $W^{[L]}$ and $b^{[L]}$ are the $L^{th}$ layer parameters.\n",
    "- Superscript $(i)$ denotes a quantity associated with the $i^{th}$ example. \n",
    "    - Example: $x^{(i)}$ is the $i^{th}$ training example.\n",
    "- Lowerscript $i$ denotes the $i^{th}$ entry of a vector.\n",
    "    - Example: $a^{[l]}_i$ denotes the $i^{th}$ entry of the $l^{th}$ layer's activations.\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "<img src=\"Structure.png\" style=\"width:650px;height:400px;\">\n",
    "<img src=\"jth_layer.png\" style=\"width:650px;height:400px;\">\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import useful packages\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import scipy\n",
    "import skimage\n",
    "\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the training and the test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = h5py.File('train_catvnoncat.h5', 'r')\n",
    "train_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "train_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "test_dataset = h5py.File('test_catvnoncat.h5', \"r\")\n",
    "test_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "test_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "train_y = train_y_orig.reshape((1, train_y_orig.shape[0]))\n",
    "test_y = test_y_orig.reshape((1, test_y_orig.shape[0]))\n",
    "\n",
    "classes = np.array(test_dataset[\"list_classes\"][:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: m_train = 209\n",
      "Number of testing examples: m_test = 50\n",
      "Height/Width of each image: num_px = 64\n",
      "Each image is of size: (64, 64, 3)\n",
      "train_set_x shape: (209, 64, 64, 3)\n",
      "train_set_y shape: (1, 209)\n",
      "test_set_x shape: (50, 64, 64, 3)\n",
      "test_set_y shape: (1, 50)\n"
     ]
    }
   ],
   "source": [
    "m_train = train_x_orig.shape[0]\n",
    "m_test = test_x_orig.shape[0]\n",
    "num_px = train_x_orig.shape[1]\n",
    "\n",
    "\n",
    "print (\"Number of training examples: m_train = \" + str(m_train))\n",
    "print (\"Number of testing examples: m_test = \" + str(m_test))\n",
    "print (\"Height/Width of each image: num_px = \" + str(num_px))\n",
    "print (\"Each image is of size: (\" + str(num_px) + \", \" + str(num_px) + \", 3)\")\n",
    "print (\"train_set_x shape: \" + str(train_x_orig.shape))\n",
    "print (\"train_set_y shape: \" + str(train_y.shape))\n",
    "print (\"test_set_x shape: \" + str(test_x_orig.shape))\n",
    "print (\"test_set_y shape: \" + str(test_y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at some more cats for a while. Stay here longer if you need to, no one will judge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 1. It's a cat picture.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD7CAYAAACscuKmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAgAElEQVR4nO19a6wlWXXet6rqvO8599G3X9PT0DP2DK9gA+lgLCIHg20RxzJ/7MgPRSRCmj9OhBVHBhIpsaNEwn9s50dkaRSc8MMx4CcIWbbRxMjKQ5jGYJuHh4ExwzTT0+/7OM86dWrnxzl997fWvef2he4+d+CsT2p11d11du3aVXXOWvtb61sSQoDD4fjOR3LcA3A4HIuBv+wOx5LAX3aHY0ngL7vDsSTwl93hWBL4y+5wLAnu6WUXkbeLyNMi8hURee/9GpTD4bj/kG+VZxeRFMCXAfwwgMsAPg3gp0MIX7x/w3M4HPcL2T189o0AvhJCeBYARORDAN4BYO7Lvrm5GS5cuHAPpwRQFnubeW9LNeV5vrc9mRSqrZyUe9shxO3DTBsR/UVYlnF/zP2VJebCfJkG1TS/raD+ExEzrrg/nkzMGA/uL0t0H2ocMF/4vCsHbu4bx2Qyfw5S+mBqxsF740L3UcmSA7cn5jiex8PGmNJAQnnIj5y9L3RsMdFtSSXd2262qjRG/fyliGPOUjMHNCeTMm4Px/pcBbWJeSbuzM+NnSF2B2M7DdPzHvTHI+IcgOdp/zKA7zvsAxcuXMClS5fu4ZTAZHB9b/vKX/yhavvac5f3tm/fvqXaBt3u3vZ4NNzbbqTqMGSIN0kSPdmj4Whv++qtXvz7KFfHleWEd3QbvUn5WD8QY3pAbu7Gc9Ur+iupXq3sbV+53VNt3SF9GdLDcaJdUccV9EBPDnm4Ezp1xTyk/AWy0x2pNtCXULseO+nU9SNXpS5fuD5UbQ9tNPe2z2229ra3zDUX+XhvOzVfXLVavO6VZtwuc33P+BuuNF8m43489ua2vs7aqdW97Te88cLe9u716+q4tsQxb67XVFulHr8ktvrxgfzqVf183BjEuUsruo+za3UAwH/48GcxD/fisx/07bHv61JEnhCRSyJy6bqZAIfDsTjcyy/7ZQDnaf9hAC/Yg0IITwJ4EgAuXrx4z4H4SbW9t11d3ThgSLPzmu8dNpWq9EuZivkWJ9MpH+pv/9Eo/oL08/jLFbQljQn9Mor51czJvTA/IEgTNlvZZDP9U5/dXJ98ZxT3szT2VwZznUXsIzVf+aMxuzx0LVVtBtXqh5jF9Ln+MI7JGEvoVOPJa5kxTWk+RqPiwG0AyNj6yPTFCO2ya1SM9Xz0dgZ7221jfVTYnTNuyCsfP7O3Xa/Ez/XMTcvSOHeZmYSU+s/4XIdYXKW1GO9Yk4eswd3LL/unATwmIo+ISBXATwH42D3053A4HiC+5V/2EEIhIv8SwJ8ASAH8ZgjhC/dtZA6H477iXsx4hBD+CMAf3aexOByOB4h7etmPA5LGVcjW5jnVlmZ/s7dtXRf2oOpVuuwwVsf1B9G/HI7sajnzWgevWNuzBeuXky8XzOeSENsatOI+yPUYeV1dzDopU1vKFzcTwmsJljksFI0Wj7NUEF/nyPjAq7QCz35oYU62O6Q1ErsKTpO3vRtX6u06CF8m+8YA0GrEle6C2I5mQ7MTZT+usmeWtqVxnSJWAAC+702P721fvnx1b7tqFkLqlYO3ASAhlkP77Pq4Mc1dUui1mjBjPw5bFPNwWYdjSeAvu8OxJPi2M+PZdKw0VlRLqqim+dFvQzLnssTYsGwV74s6i33UiTKyZmUoY9sw1/0LmeqVfWOk8dO5LI3IFN1GS9uEzPhQcBeq6cERVwDQHRrukM43JnNxMtF9JPRbMRjrPiYUabZai8cl+2hEGqMJHuKIt95upEFb5lpA99bScs06U15sLus+1lajexh6Orinm8f+X/vGx1Xb2de8bG/7yovX9rata8c0qA1OkpRcwkMiFpndtNRbMXmw1JvD4fg2gr/sDseSwF92h2NJ8G3osxPE7h5MjQFAjfzBMeUy9AfaxxNOiCjnhyuyG50ZmoU/VTPhmxxKm5hQ3Wot+peTEMdl/bPVZkpt2mcfkY/NLrDNNuPQTg6dBYByEj9YqDa7xsAtuv9tWgdg+nG9bvxyGtdKwyTJkG/bJfqrELt2QHSmue+9bvT16zS/1Zo5F9Gx+dDMVae+t/2qH/wHevydtb3tLIt9ZBV9X9IsjiMxPrui3mihJTNvp7qHdvHjCD/b/svucCwJ/GV3OJYE335mPKWYFbs6ZbbI2YSdLxAQyGwqzNcdZ0MVRpCBRSTYWByMNO3UpCRtaz5z4tjA0HJsMWcJmerB5svHA20fQxr/Lpm+lqKrt2L/oaf7Z6+E6Tt7Le0am/t6InPSTyiYGjMuQ0GuzEZH52iXlBPP3pAV81CiH8b16lKefVnEx71uMuxyOtctQ0U+9vcf3ds++do3qjYZxETPlXaMrhudaKvjWkTxVpvmuSJ7vUkuSWfFzDcFUibVhmprzHL1k/3hnPEzc1scDsd3FPxldziWBN92Znw53t7bvnX5K6qN5aFskNWElo7HFO1lV7pzMoMzI1k1oLaETNqxWaVmU1VMW06uQT/XTECVVsgVKxD0xeyS22AlpRrkJ7Bemj2OV7qbNX2ht2lFn6+zYuZjhT63T4ePxSvIvcqNmd0kc1olKAHoUXIKP6lixsHuBScyAcCYTHJmQowOB8Z0b7ul/g189Q+9JQ5j7RH9wfzG3uZKK67ajzvazG6msf80Gag2NcfkGnV0gChOkKs0SbRbVp3dHCt0os4zv8nhcHwnwV92h2NJ4C+7w7Ek+Dbx2cn37EeBgO1bRjeepJmtf5lTGBdrre/2tTAESAY6Mf42ZyuxyKSN6BqMY58jmw1Gvq31xRkrJC9c7tOGj+NaM1FnJ1px/7mb0Te0yVBMX7WMA3urS/NN52oYIUaODrxqhC/XmvFYluu2GXwNulET48/fpnvToci7pGJ/ow6m+QCgpOtkKnXLSEJ36T498vfOq7ZzF98Wx59oX1zomahVaP3BRFVmGclYB31ujvrj7Uqqr4Vk6TEyKqdilVAOgP+yOxxLAn/ZHY4lwbeHGV9Gs6d/NdJtuzu6Mghro49NtZUR7RcTpmNMySGO1NpXFelgKsuayNVU2a0KXN7HGvGcUMPBajbJpE/VTGxk3EY7RqH1iU66uqXpHqb97BywVS803qblq2hY3ZHugzXgU6bXDJ/ZIS24HZOUpCstxT6Mx6Ci4VKTeMQ064g09MbQ453Qs/P493y37n+D6Tbj9vEIqY9gXC/W0ytMaSguRzYg3YzcRGaWo/nnLmbzc1jtRv9ldziWBP6yOxxLAn/ZHY4lwUvUZzeZUd1Yw+3qc8/tbe/2NYUxKaJPk4+1f8P0VVBhkyaDilw5KwxYI3+Ts7rGpfHP6NRW2IJruFn/qqEopfla6xxyOzYlhFvkA7/sZMzC2jFz1R3GQVbMGKu0YNCi7LiG9dkPWbdgao/FP9t13cdqM64xjMZ91cbj6pPoI6r6ZO1GPNfGel21vUA++4Cc/ZN1fW+bRAGeeviMagPVKrB1BpQ4J62ldI1o5ZiubTjS6ydMpfJz1d3V933A+0Z7Pr1D496Lzy4ivyki10Tk8/S3DRH5hIg8M/t//W79OByO48VRzPj/AeDt5m/vBfBUCOExAE/N9h0Ox0sYdzXjQwh/LiIXzJ/fAeAts+0PAvgkgPfct1EFTU3svPDM3va16zHrzZrqnHk1seVxVLkmomqMqZ5Txlph6BmZR+3N0/DGfjN7tRntr422nv4xUTIljX9syiL1iZJZb+i2BkXesZ6ZzSgbkL66CcJTJaWqJIZQq+rfhtuk5W4FJU6REMWESyWba+GAt4rpQ2j8HBlnphTDgu+7Ea9guo0eiba56JTudWPNlALnNDtrJlMkW78XqeCvP39Tj6NHZrzhDrnHNKFx6dcAkxG5TYl2E5JZn6URXFHHzG05HKdDCFcAYPb/qW+xH4fDsSA88NV4EXlCRC6JyKXr16/f/QMOh+OB4Ftdjb8qImdDCFdE5CyAa/MODCE8CeBJALh48eJhRSb3UBZ6VXbr2ot72wMKMSon2owf0WroxEQwJbSyK2QeiSmzmlIVzdxKLJNpzVFPQ1PBlCuadoda3y3Qyv35U1qnbI2i4W7eiiahNfvYUuuY5JQqR5ORwEFqTGReAbY3hU1yNp9T89vAq9tmQR+bFMnXozm4rYMelfS1lU/jclArFBmXG9GPHkXvrTarqq3VjP1fG8bPdU1F2kAX0DhhDdWDWZLpbtzfpUqzTz+/qw7b7vGzaROsYv8tWvhvZnrJPZN4XChN/OXsebTy54xv9Zf9YwDeOdt+J4CPfov9OByOBeEo1NtvA/h/AF4hIpdF5F0A3g/gh0XkGQA/PNt3OBwvYRxlNf6n5zS9bc7fHQ7HSxAvyQi6cqT9ne52FKko8hgJNs51VFjB4hUmu6rIo38fJvE49tEBHOqejelYIf9pX4mnCfvNJguL6UGzrlAnwUKSjVfUFQA0SSRho6191FqVo/zmC3HwOkMltRF6vG4R+xBDRbJ/uGqorA4pLfSI5jMMIEbG/2bwPcw4BdHMd5+086smyo/XHFhkZGhUK0+dXd3b3nhYZ71pGF+ffPYujeP5XX1vd/okIGruZ4spTRpjw2jbV0lfXixNOcu0tBQow2PjHY4lgb/sDseS4CVkxlOJoN0XVcvOdoyaG48jvcGJLwDQ4CqoY0155ZT4P2a6x1AVusqqbsso2o5N60PNeNMHR9SNcmsWs2Y90SzGdOwQJWUFJapMMZKJaRN+mDZbNwIYGZmP/eEhVW1p+2RHuxNN1qDrxjFu9fQ9Yw3A9RU9jiHNMQcp2tJeVZr/gaFBBxRdl9LcVFt6vG96y2vjeDe0Bp2GjVBjfX86rxHY6NN+mOjxZxN2D+PfW8YVXaPKs5bqvFPkILPVXQn+y+5wLAn8ZXc4lgT+sjscS4KXjs9OopK7V/9ONfW7FGNZRh9PjGgEiyTAhNJydhJTUhXRfVC5tX0ZVCwukZIIgy3tzH6XTULijDirB8/KGezrp0ZwkkNkGzXt5zLVx+WQbe27CmezGd+Qte6ZytkZ2kzCuG09xUoax9gmQY2nv6FpVf6cLTfMoczse7eMbz8J87MMuX5eRmN69NGT6rjX/qPvp8Hr0tEBRD8a8QoJTE1GlOZ3NNB+adLZCupDrduYn+JGjWrCGQ5TZk584j67w+Hwl93hWBIs3Iy/YxKJEQGYdKO23PWvf1W1jXPKdGPBCmPGh5K04Y1uPJvMLFRgKwlxpFlWMRQJUzdkYw2NnjdnxHWa2uSsSNy31N6ExsyiES0zjhWKuKqZOlc8rxMyx22Jp82VeOut1h67ITzC/dlxcTs3lBfPVaMer7lqf17oOq3Z2qaIQma8KmbeOJrRWrE71Cln2L3m9br0cvt8jJoLMHOqtu0s0POSsWukL4bN64mh3tjV44jF8UQ/w0JZjLW67j+duWI2c1CNYX6Tw+H4ToK/7A7HkmCxZnwYAMMvTDeNaMT4ZjTdu7dv68+N40o9J8IEs+LeH8WoueFAJ8lwCBaXBEoybZbVq1SV06xS16ps31LUk3FJAtllnAQyPXfcX7HCE2ym0akbqXUnSCPOtLErwCu76yZirEtCDlaHj6PwuIyTdXlq9Dm7Blyjg5OVeO5WTc/pzV4cR63aVG2PnF3b275yI67if+NaVx3H5u6K9RNopfvhU1Fa+7tefUEdJrRSH0yUHN/d/WvdJAKiKvTqZ6JZo3FV9b1g16DkM5iTcZJPq6PnqrIyvbYkm/9K+y+7w7Ek8Jfd4VgS+MvucCwJFuuzjwcIL/41AECM35LfukWH6fI449GQtskXN9TbrZ0oVDkyvjLTchyZJXoYqJJqxMT4biMS+bu9Hcd0Y1evD2wN4tqBzcJiwYpG11BeIVJND5Hu+poRhlih6Cm7rjBmgUjqfnVFR4V943ac45ZZO+CsQB6v/WXgzKtVQwUFzjbjclumkzThNRLdmJOA6PWteG/HJvJQrzGYLMCVuP+GV5/b2+5srqnjQuA+TWQj7QfTxoIeFRp/1XBguYo2NOPn9Q3qIzXRkZWV6Kd3zp5VbbXVaVGmrHoJ8+C/7A7HksBfdodjSbBQMz5MSky6U5M3qWrzdutGNOMHPa0bP+iTGU8RdKORFqjoUaXSodE2y0nognXDxmNtSocimn2jRNMnTFftUBVUS5F0KRmjbxIzSkqu6Rk9+OJaTPhpkQ3+8hO6MmmHtNEzozk2ohJSBbkywZSoapPp3qxrX2arG+exQWaljR1bpwSXjZZ+lDgSUchUtxVjB2SqG1YOwyGbz7FxaIRJmBK0muxrpNH3yCPR9M2q2kQWKjkWbN0ldvsOEa9oUp+nWvqe1bPY5zDX4y+5EiyXyjIPVroS6wy0T2szvrLSAQAkRmue4b/sDseSwF92h2NJ4C+7w7EkWKjPXpYlerszf7zUftFzf3d5b3t3VxcEG5OPMyb9952uLlvLGuRjU7KZfUhOFLMhoGnCuu7a/9sexP7bJKiYWw1v+lxqwibLEI/NjRN8g/r/xnb0m8+tddRx653oD5bGzy0oFJhrom3vaHqQ/f6RobJYk5ypMVtXjvXOG/v8bQqDJb/filbWKRy3YQQZAo1jQNeSGVpLiV6Y9ZMOUY7r6yvxMBv3ymXCTcnwoAROrM8eO2oSVXaioddBeMw7po+84HNT+K3Rtk+b0WdvrOqy0pV6A8B+ARDGUco/nReRPxORL4nIF0Tk3bO/b4jIJ0Tkmdn/63fry+FwHB+OYsYXAH4hhPAqAG8C8HMi8moA7wXwVAjhMQBPzfYdDsdLFEep9XYFwJXZ9q6IfAnAOQDvAPCW2WEfBPBJAO85rK+yDBjNIuBGPZ25dPNG1IYf9HQEXUFUy5DopKEph1ySOVQ3Agdsgq61WMPNZJSR2drvGx07ipSrkP3fLayYQty2ZZfYLC5tlBVRPjeJ/toxIuRnTzG9osfPUVxjimKzZYG4hLNhH5XWHmuF7NM3I5eEzwXoCMY60UHWBN+kjLi2yczrj+J1c3mp0nB0Y7rvQzMOzj5Tmn+GimS3Uiz1Jnys+RxNCevddQydOaH5zo0oRTFh95PKVVkRjUp037Kaznqr1qZmvNyLGa9OJnIBwOsBfArA6dkXwZ0vBFvU2uFwvIRw5JddRFYA/B6Anw8h7HwTn3tCRC6JyKVb2927f8DhcDwQHOllF5EKpi/6b4UQfn/256sicnbWfhbAtYM+G0J4MoRwMYRwcWN15aBDHA7HAnBXn12mPMwHAHwphPCr1PQxAO8E8P7Z/x+969lCiaKY+qI6ywjIKZutZ3z2krLbegMKlzWikixEuGJEGqvUltC5s8TqrtNnDC/HApFDOvdgbOq5UZthpFCS77bPjyZ/Kyefcnug1w6YXrECiFXO+iJ/NTPlf5kBszQUt7Gajg115bBjS6lVyb/ndZCzq9qXZWWVhpnvbj+uyTDNx74xAEwmcd9mxPEYexSGHQobEktzbKi35BBVIkZKc99o6CzDHv2uJmatiesLDujZsWtBY6F1CzGv7p7Sznzd+KPw7G8G8M8A/I2IfG72t3+L6Uv+ERF5F4CvA/jJI/TlcDiOCUdZjf/fmP918bb7OxyHw/GgsNAIujRN0GlNzZueEYtkEzk35vmEqInuMJr7mRGtbJEZ2DIqCRylxPQGm4DTcZCYgjErWQxilzLxjHYFCoqgqxnTl7OmLC2X0HdqhTLutg0FOCJBjBUjbMHUG9N8Yssc07h6pn+m5VpkjtYOEbe0Yg11ClPkCLr1pjbje3Qvvn5Fr/te343mLlNKa22dUVYURJfumGxHcrFGlKkYzDMmXFYsaDMbwscaN4FpVprTxLgaJXVZmMi4nDoZ0Hxsj/S5eNe+I9lsPxziZnhsvMOxJPCX3eFYEizUjJdEUG9OzcLSRDC1KHoqmCSZ7V40mYdkyzzU1sNfpci4zJYtpdNxpN041993Ga9yWt1u6pMWipEac7yeRjNNbJIMrbwaQgIZuTI1GsbOUM/HmEzT1MwBl6Wqkc740K7ssi6ccVcalF3D05ilNuuGouRMGaoVup+8gn3VJORcuhz14K/39XWyO8FMS2FM1UdOU4KLuWkDel5YBKU0AhLZhPatGa8i6uaLV/BPZ2F+RguayIpxverjyAjl5DIkVfPs0BSPzfjzmZvmZrzD4fCX3eFYFvjL7nAsCRbrs0uCrD6lTRqJoYzIH9wdaH/kVi/6eSvkkzZsSWXataIUE9rfJZGIzEYQ0FpC09BErK/O2vB1Q6+BtOf7Rr9+ROIb+UT7fysZ++yxz0GujyuYckysX0cReiz0aOsh0/e8VUkP5M8r/Y7M+KvUttZuqCYut/y5Z67ubf/5c9vquKs0PystncmV0ulkGP3tF29pQdKHN+K564Zy5ejLrdtxfaAY6rWDjNeJ9vnsTE3OF/qoduI4Ns+31XFV6qIoNHU4GsUadEOqZbjS1OHlmxv0OUNdj0fTm2GFRRn+y+5wLAn8ZXc4lgSLLf+UJJCZVlYZdLLL7Z2oO3drR7dNSF+9QWWG9uvHkUllGvMh0VVkf+50jTlXIXPOmPgcocc02dDo3Y1ovAOjDZ/TsZZ+bLdYSy1uj4wWHpeBDkakg3uckJswMaIOnGgzGusxVsgVYI/B9lEhH2hzo6Xarm/He3jpuVgTYNu4LnUSomg19eOYUWRZp0ba7Wa8TAHaxCBO0OF7PTbJKHU240vdJipJxpybIvvq66t72488rl1AksBHMdbP3KSI5yuovkGW6j5Wic5MgjHjZ9djS6Groc5tcTgc31Hwl93hWBL4y+5wLAkW67OLALUpfTCkEs0AcO1WzHjKx9ofaRK11SA/0UbEcuacDWFlSoI/NzQ+5JD8wZHxUU+tR2qlQ7rguyNTm4586p7RrGQ/fdWIXTZpTWBIXGFhBApZYNFGR+qst/h3U8kYgcJnLSvHSwksyJCYUNE10mRvNjWd9JdffnFvu8dlqs1aypgWRnp9XQcgo/jQNcq+S0u9ptMnGrQ0zwRrVOwQhZubtRRVx8CIV2jqzfjESXwOKq1IlZ0s9RoG95gbn72k+8vrLCqlDkBSktCKKVdezN4ZD5d1OBz+sjscy4LFmvHAnuDZcGdX/XmHqLeG+QpaIeuFRSladW2bloGpJm3OsGndJU03G/xWkBm1ta3NSqbzTrSjWXnLlKGa0BgTE3HF4hjtuj759oApO86O031wWSox1NuE7Fbu3Wq+pySOURgNPeUBKSrHUIUr0a0ZG5Pz1m6cE3YtGrZ0E1FjxmvSWvQrpLtnrmWHfCVrgDPltTEi+i6xfg1tGxNZm/XGT8iiuZ7UoxnfNK4odz+2Gnp0voJEKcZGoCIn8Y3CuCHDmQtU2rET/Jfd4VgS+MvucCwJFmzGC8Ls+yUf6hXVhFYkjXWOJiXxd1S5UG338Yp7paolopuUxLLbo6qwpV21ny8b/OLNuOrOpvTLN3XCwlWKHrtR6pVXrph6u6tNrj6b7rQ63KpYQWoalxnjmNiEQCZnZmWgVcSYmUeuJBooatCYz51OTFzpGoENTvJheetRYVeY43hT402M6ZmoURJOraYf27VmvNfXjCDgLXKNztPjntZX1XFIaPU86GcnBBIjCTpZB0LCGZUmbevnG2nsk+WzAaAkc72/vbW3nefaPezuxiIrA3OduzO3qbAS2QT/ZXc4lgT+sjscSwJ/2R2OJcGCI+iwlyU06umoMyG/0eqTbxD31uSst9SWtCWxRVu6qRMjnYYkXHBrV2c4saikLc80IjrvxnYc/7lM++zfdSrurzV05tIWKVXuK3OcU+TdkEUu1GHY3o3+4Hio/Tr22biskI3GUi58sGsfcZvXOjLjVFerse32beOj0twFWmPIrfAl7VuxyBXqv0brM8Hcl9M0342G9rfLG3Fc1QaVPF47q44LtTO0o4UnMKFSTmaNJICENRMS8KjqZzOwEIUpt5z0Iu08uUXZnzc0PX3z+s297a2bWmN/OKMVx/k9+OwiUheRvxCRvxKRL4jIL8/+/oiIfEpEnhGRD4tI9W59ORyO48NRzPgRgLeGEL4XwOsAvF1E3gTgVwD8WgjhMQC3AbzrwQ3T4XDcK45S6y0AuLPmX5n9CwDeCuBnZn//IIBfAvAbd+9vam4M+sbsIzO+boThVurRNNtcjaZYPrbJAEQ7meSRBtE/JzrRLBuPtQmrxCaMycYMWEHjfe66NrfOFNGcO7mmtdnOb8b9VPS5+1SG6SsvxD6/fEOb6je2ogvR3dXuUEGZIAldc2kSfrgi68RkwqQUlVclnb/MHkcujxUcyVWUXzzOVlnlSEcx7kSbxCwmJOpQyXTSTa0ejcq2oe8eonEkFDUnzQ11nFQ2406wYZXcqSnnRbRcoNdJxBzHY060ERwyciUp+WfQ1/TakAQ3hiPtfg5nEaLlvYpXiEg6q+B6DcAnAHwVwFYIe3GElwGcO0pfDofjeHCklz2EMAkhvA7AwwDeCOBVBx120GdF5AkRuSQil66bRQWHw7E4fFPUWwhhC8AnAbwJwJrIXq2khwG8MOczT4YQLoYQLp480bmXsTocjnvAXX12ETkJYBxC2BKRBoAfwnRx7s8A/ASADwF4J4CP3vVsIYaj9nZ7qmlMeuoNE5bZqDHdFtsK42+P2KcZmjLETNNR/w1DkRQkCFkYJYQJ+elMa40NnXSFwmr7ZhwvPxl9dl47AHRYcJWz0kxI77Wd2OfVm2btg0Ix2W+26w8ZrYvUJvo7vySKjf30qllLKUjj/AWzbrFLGWZ1qm2W9fU9G5NBaMNxN9txrWaH1jMef9iGrNLnzHWWtN9eiz82WdP88HAdA5s5VrBPbX8fua4f+eKpUS3hMZrrBD2bFaIbmy3t25eI9F2tqSnGwUzAI6vMf6WPwrOfBfBBEUkxtQQ+EkL4uIh8EcCHROQ/AfgsgA8coS+Hw3FMOMpq/F8DeP0Bf38WU//d4XB8G2ChEXRhMsZ46zoA4BZFAwGaRqubUo3/Qb0AACAASURBVLUTygoakd6YmGwtTvy/cVtTUmzd1Zvz439Y1703MjQGC0XQZsNE/DH9sdXT9AlTgju7mlJrckleGofNzPvGbjQRn72qzfjTVAoppbubmsy5esaRcaoJ+Ygz58idMPr112/EUk4v3NRu2Q6V2HqIsuNWW2Ydl7IC19qaUuMAQ6a1zq5rOnNAGXcD4zaxC7TaiZFxqS0/zXM8MeWf2KxPzSvDDxYLc5hnIlDbPlqOjs0oYnHj1Lo6rp3HzLyxoZ3vUG/V2mcwDx4b73AsCfxldziWBIs148sSk1nQfzBJ9hmZi/V0/go5J7GkZuV1NIhmsTXnGrTKuUtlgPrGHOIVbCvLW6FV1CYxBDa5Y8AyzSa5Y5dE0WzZpc3GwSvpxopXem82KYR1EdQCsO5C6eklVvuNNOlY+npkMnKuUWTf0CRgnKHV4jFdc8usFtdX51eT5el5zfkoNlE31XuvbMVxFPsSQQ6WHi8Hmj1IWb1ubBgOFkmp6FVw5drxcWbChaquBhM5iSKOPyMWZmNNC2zwvbCRiHfc4Mohq/H+y+5wLAn8ZXc4lgT+sjscS4LFilcEAHeyr0x2Dkc65SZDi/Wzi5xEDIxPzVlvGy0jGkjb7DJZGqTCpY9MoBPrlfOph0YjfMzjN/1n6fxorxF9bkh+v9V8X6f1grWmFZIkbXQuh2XGMckp2nBgSxTTcazrbsQ2vnY9+rZ27eAN37W2t71DPvsVI3KxQ65yYjTlHz4TKbvTqyQqeaOrjrtxK9KsJ9qaVm1SxuTVF6/sbb/wpc+r406sRVquZko2Z61ICUrbRO+xsCnfTrN2EPq8RmApXdL6T+NcVZs6wpKfl6otfT27N2ky//fbf9kdjiWBv+wOx5Jg4VVck5nZkxod84KohO5Qm7enOtFUYlOdo90AoEpJGyu2NBTZWJNDvuN05Jpu26VIrRHTIGYcrF1XmszfDRZksJr1tM3BausNfZvOtSn54pAoQpU0lGtXY4dMdxsZV6NoO26ysgg3SZO9NGb8WieavpsnKCrMmNn5mO+LHgeLXjx3JUbrse4/oDX8bb2AEd3rm9ejJvv//T+fUsdtknn+0IqO0Dt3KlJgnXMnVVvSJm25LJ47mIenpMqtkuq2hKMb6VYb2UD9GUPp3tHvk0M/43A4lgL+sjscSwJ/2R2OJcFCfXYRQTKreZVmttxy9LsGhrZQ4g1ELVh/OGW/3IQTNprRh0xJhCEYv7k7iPu9rvYNWZySQ13bNUuvUYniuvYh11aiz2qz2XYoQ47XHFqi52qTypKNzFzxZQcqHT3um+ukcOJE5tN3Gd0nWwab1wSCLaPM2vZEE902c9qnDLthrn3ZbRojH9cwwpcnSQQkM9l9XVpXGNHayleffVEd9xW6tE5dvxaPn4603OM3dLbmyTMn4rg65L+bsFrOb8xM/1XKpEsn839/VQ0+s1Zz595YOprhv+wOx5LAX3aHY0mwcOpNKneoN31qDiyrVvV3EFuIbPmKiRYKlL5lmD2UZN+GyXxTZ70dTcJaVY/xKkV/FSRCUTWZRi2i1xqm/BO7E32jC15jLXfK7DIyedjpx3MbWTi0qTxWQZ/rm4y1IVFeYvLNhNwhjhezdM8aqW3sjvScblNmIZvnAxOFxwzVdq77IMsdbXJrVsx94Sg5e89S6pMjJ62u3/WdGIX39Wuapnz+eqT9vvj8DdX2XQ9FgYlHzp/a2662W+q4hKLh1k/q8lJtibNcZTdE9BjZ1S1MXYTCzXiHw3EH/rI7HEuCxZvx1akZW6nrIH+O2pJSmyg7FDFVSePnmtZko1XafKhXfQsql8MrthOTUFBSH+sdHUnFiTArLM5gTELu0ZZM4gQgK53carA5Go+z0W9Xe3G/UzN6fXRtOyTbzGY7YJONdB8JCShUWR050X1s0BzsDLVLskuuxspKdF3axq0ZUpJMpaLv2UCVO4rXXJr5Tsj9qZoIusEomuclsRo2epEjM3tD7dYMyJ/YMmzCCySc8ez1mKCzvqYr+26S6X6h1FF4gdyoFiXd2ASoYsJRm3ocd8QrJlYGm+C/7A7HksBfdodjSeAvu8OxJFhsBF2SIm1MKYkTp7Tf0iQt97xnqaAIjk6rmGiplL67ShNBV1L0lJBXnVp970DiAUZbcHM9UiRJGn21HSv+QIKZlq4KNC5bTqleiXPALTtdI0xJlFdpfDSO8htS2tQ+tpHaxPiGHMg2ohJYVVtCiiMFzdoErwlwqeR6XWvDVzLy2c18bJEvK3xfTPTlyY3oH1t/fjAimpLqEZilGlW3wEZV8k/iyGQ43iDtfxYv7WxrkY4z/XjcGCbqMcT9zc2YYWczQydEt+W5fubuRFLayFHGkX/ZZ2WbPysiH5/tPyIinxKRZ0Tkw6IKXTkcjpcavhkz/t0AvkT7vwLg10IIjwG4DeBd93NgDofj/uJIZryIPAzgnwD4zwD+tUxVBd4K4Gdmh3wQwC8B+I1DO0oySHMTAHDq4XOq6fy5jb3tW9e2VBtXWq01IvXWWdUmIVvkPROhV5BOXIPMORtxxAk6LaMBxlrubPpWrLlFprU1Fyt0LUyzAEB7NUZdsX74qp4OCGnu39gxZitRbMN5pYmgNenKfVFXND+0XZjkCxaeqGfWHSLt+YKSbozb0SGKanvLmPFb0RRu1aJPxWY7AKy04n26vaPLfvG1NWukyz8o5h5ntQfZy0lMVBvXDLi9G03rgakJwIlTXUNT8vOSj2JbzSRRscs2NGb8nfJPtiwU46i/7L8O4BcRKeQTALZC2HM2LgM4d9AHHQ7HSwN3fdlF5McAXAshcMW4g8RvDgzKFZEnROSSiFy6fnProEMcDscCcBQz/s0AflxEfhRAHUAH01/6NRHJZr/uDwN44aAPhxCeBPAkAFx8/SvnR+k7HI4HiqPUZ38fgPcBgIi8BcC/CSH8rIj8DoCfAPAhAO8E8NG7ni2pAPWHAACNdU29tSmk8sYV7XdsU4liJYZoKJI6hZtunNR1sli8UFFeJntoQv6wDXVNyd/urJD/NDK68eRbWSpIyJhqNLRPdu78Q/HcJEp4K9VjzPvRl2VqCQCe2yLBTPA1q8Mg6XxNebbRClVzzlBvXJesZcRIVM080rI3BiCHMfd7mq5qk/Y/hxLbbMdBj7MR54t/Nshnt9W469TWm5iyz0S32RBn3s0po2+3b7L7yLffNXUImS4bDKLPvrGu13Q4C25o+og+u611R2Od23J3vAfTxbqvYOrDf+Ae+nI4HA8Y31RQTQjhkwA+Odt+FsAb7/+QHA7Hg8CCs95SIOsAAGqdE6rpzEMx8b+/rcv7bFM0Um8QzZfrN3TZXdmgCDcjoM3VpupEaaytaxqnTtl4wZicbI7u9qP5OTY6cDu70RRr1rR5O0Icf3eomtBZ34zjR+x/dPu6Pq4V45eKoE3f20PKjCIzvlnV88Ea+5nJZivJXOySvZuZkl2rjXht7aZ2SVgzjpVEMiP0oajUtjZbR0RRMaU06Gt6rUnn7o60GV/j6yQXsAl9X6pZnMebY31jOCOubl07ujZmYAdGNz4n+nFk2hL09raZqj29Y6jljMx44zoOZjUNbFltfR6Hw7EU8Jfd4VgSLNaMRwIkU0GItKNX49dPRbO++dxl1bZ1O5r1t25Hk2fU099VQlFyFZMswavstUr8nBTaDA6d6ApYgY2sGs2qWiMKW1Qb+rgJRVJZk42F0JpNbaYxY5Blsa2+ojXLQjW6Ly92b6m2bdKCY3nnIMZ0JJuzMBLRBZn/nPjRSvVx5zfi47PW1nMgSZyDMo1uR62mj6tmsY/MuF4Dsmm3d+J9qtloPWI8ekPtUrE+YL1OyVbBmLvMNBh2Ysj6haYIFicHKbEJQzJz9KG9zj6JZbx4Iz7fAyPAUiVdwrzQ13lHft2WImP4L7vDsSTwl93hWBL4y+5wLAkW7LMLBDOapKJ1tdsnog9vs8Fq5Cuyv21D9PsUTVYt5lMwLHphI9y4rE4w0XX9bvSV892dOPaKyXCissQ7A02RsD/YNGWARiRwUCEaqtrU0YBDxBJE2zqBCjldT0r+5Ei7f0hJGMJ+42fklk5I5CKr6/nukD5+q6HXSPIy+uZ5iGdodwzVWYtzNRno9ZMx7a9R2Wpb4omj4WxEYZsUM1dWiJo196xF4ikNUxKa+7TiokzHqmcsOSh9ZO9Tc3eHdDGT0tQVoHoKNlJwsCde4brxDsfSw192h2NJsGAzvkTYi/gyFAmZc62WpmfWKcqtSaZYahIiOLjJCkrUyQRiWq7R1GpatXak1DJL35FZ2ST9c0sF1UifLim1GZ9RMs3tWzrlt96KkXLtlfNxvDXj8qx29rY7K9rl2SUaJ2GXxJif+ZDLP+m28TiOcUyXZssurVAkny27lPTjdWd0n9ptbcazubtthC0qRBemZMYPDZu5TVruE1NeistvbW7GUk19k0iycTO6aBwdCQBDSi7p9fUYmbVk98fq6SU0B2MzxpIoRtb1sxLwYxILsaIod1jnQ6o/+S+7w7Es8Jfd4VgS+MvucCwJFuuzhxzIvzHdLnSYZ60ZffHTDz2k2niQuzsxnNCWPB5RJtDY1EfjqsQl+eK2FFuDQiorRjieaaJurOKL3NBrXF64flrXixtOUtrW6xYVohgnRB2mqV472NyIVNxjZzUtV6XrHpIQQlnYTKsIW8NtTKGkXaqPtmrENtorcS1hYjLi8nFc31hZjfe2ZUoZ5714PxMzjiplDLKOYm9X33fOhBQTiso67KdPxczK7V2dMblCvr0VLeEMwWFmRCkoHJojozOzDsJZmFbkdEJrK3YdSp2LHHUrbT+ZTPsPByrGzcYwt8XhcHxHwV92h2NJsFgzviyA0bXpdt5TTWmFyhWbEkGs+c5RVcGY6hwxZqmgOumO13i7rqm3lLKk0ky3CZUxYgpwbHTAt3fjGEujtS4kQLBhdO+rRDVxqZ9KqsfRIfrqsQunVds3rsXIvltUTvi0udObFSrLbL7yOY4tJ1P6FRc21HErG2vxMwM9B2sb0ZxsdeJxjZbO4Nu5EaMBeX4BIMnifepT/9tdfa6CXJR1chkA4CTRbY1mdKmGuY1Oi+dKTfRbhcx4HcGpaTQ2szMjBceege2jJJOftftsaTJum1hzXQ6L2JvCf9kdjiWBv+wOx5JgwavxBWR0e7o56Ju2uNk0Yg3rm9F8ZPN8YmRzhcweU6UHKZk5bPBYky2h1WcbWcb7FTpXq6GnsZxEk3Cnq12NrRtRiMOKGIASXNqdaH5WKybKj5I7HjqjTetHqYzW316JK847ZjV+nSK8Cru0S4kmjz4a3YRXvPJRdVhrLZrnoat1A082YhTa2snYh41K5NXz0ohG9ClijLXlKhXNCmxSQs7Zc0bb8GxcgU9JKEPMA8Ir8GLGwfu2gmyaxnGRzNy+1XJ2BcSwK1vsloTYSatuznXISn02ex4PM+b9l93hWBL4y+5wLAn8ZXc4lgQLpt4Cwh3KY6iFCkDJ+LWmjrJaO0F+F/k7eV/TdywqGUxaUMLCgCwaaMs/5UR/mcyljHzFpBoz88pETyNnxIlZV5iQyIPYqDPWSR9F2qycaDopIR+y1dQRehfIZz3zzLW97aEpZXw1j/PRMGIQ50jD/zWve/Xe9sZJ7Q9nNAeV1ppqU6WSKdJuNNSa7BnRrI1OR7UF6j9rxbmZGDqTSzKdPKuFTDu0rpAStWf93yrNQa1iNeUpE82cm314psYyk3XJgilbZh2HyzmXZbyW1KzprDRZ61817YldHqaZcdT67F8DsItp0GkRQrgoIhsAPgzgAoCvAfinIYTbR+nP4XAsHt+MGf+DIYTXhRAuzvbfC+CpEMJjAJ6a7Tscjpco7sWMfweAt8y2P4hpDbj3HPqJcgLpTemgkGuBAGHzyFATLaLiJmTeFgNtxg+pLNA+2oxol5TouyzTNA5HzaX7aJb4uVotms+DTI9jaytSXlZL4MxmjH6zNE5jPZqcTdKiTwwVxCaypRjXV2P/Z9bjGD+/pc14KvaK8x3tCrz6lS/b217tEA1qL4ZumaUHE7qHCRFCpdFO6+3EuRoZnfSM7llnlSLcjHnbIP399TNnVFutFts4OYqjMu3+xIyRI9kqxn5u1Lj8E7l5xkXrkiBGMbGUrhzYNrJCHNRWM27CnQg6mwjEOOovewDwpyLyGRF5Yva30yGEKwAw+//U3E87HI5jx1F/2d8cQnhBRE4B+ISI/O1RTzD7cngCAF720MZdjnY4HA8KR/plDyG8MPv/GoA/wLRU81UROQsAs/+vzfnskyGEiyGEiydNxVSHw7E43PWXXURaAJIQwu5s+0cA/EcAHwPwTgDvn/3/0bufThAkPbAlqFhDTVdxXbI6+bJFS1N0Qp+bmKwmFg9g+i7LtLhlhXy8zIRlsmigkK/fMCKKxTj6Z7dvaFHJfi+Oa2jWJrIW+XU5iVamehycHRYOoYLObER/+zPParGQCq1bvP5V51Tb6ZMxVJepnEmhfWqmoTIjyKB8dq4rZ+6LkKrisKdDboXmn+vppaZeXJvWOjqrmgLkdZYc8dxWgDMlvzkz/BVTcRVD2bFrXtAz3DOlo/lOW3qMQ685dNnW4ONyzHbtoDLLpDssXPYoZvxpAH8wc/wzAP8zhPDHIvJpAB8RkXcB+DqAnzxCXw6H45hw15c9hPAsgO894O83AbztQQzK4XDcfyw46y1EgeuRqVs0ITPelG5ig6VCFI8VuZiQ+VxaIQQyJdmMr1Y17cQiGpbyUiWVqa1uIv5yogRXO9rkLEmorDBld9mV6ZFGWlHqa2FXKB9pCmm3S9r29XgtJ5raFXjsfIyG++6X6agzji5jai/J9OMiHDm4T7Cc6EHqLzE27OaZmBFXbelIwZyeERYVaZlIuxUy3VPjeqlx0BAntrQxDathtAdzosB2DT3I0W9MTZZBXydTwSYwU2VrhjDfEOdxTEyEaLVysHvM8Nh4h2NJ4C+7w7Ek8Jfd4VgSLNhnL/d8dUW1AQgUrigmXJH9wYR88Wpd+3isKFIaf1g4xJTcogTWLyd/dV8KEe+TD2aVZBrRh8+Nj5cXMWw1q5jpJ982J1/QCmvm4+jL9ns6i4yFHxPy8R49odcVHjkT9dTFEDYTWj8pKSvQZorx/CSGRmSqE1xzzvjKPAfr6+uqjb1SdmVrRrSyTvNt11lYuDOnZ6y0hdRojPYXkKmxqhGLzHIOdaX5MGGrY6LRysSubzAotNi0jAoOpdXjr06m83hYz/7L7nAsCfxldziWBMdAvU3N2pAb2kmVFzYGDIUpsXVUrRvaLGExSm0+BzbrOexJLEVCh1mjiLgbzuSy5niVSllVhrZEFUXJGVNspxtN8kYSKbtR0EIfEzLnxtZN6MX93RejhvxmTbsaK/U45mAytCbkQrCghhh3IsniuaqGfgSZviz0WDV0KVOiY5OJFsgkT0lks2Lct1RlgM03ZPk6Le1Zq8UxJmKz0iLqph5BrnTj4/irJsJtTPfailGyt1iGg7enIDM+1/esWZvtH1Kz2X/ZHY4lgb/sDseSYOFm/B1z2mp5sekutmQSm2ZkztlV+yShFWwTQRdSNm/IbjJWD5vudpWa7aqSTEK7Alwh96K5qsfIq8M3r++otm4/tiWDmBRSybQr0KDzjXvajN+9GiPvJtdjH+mqdnmKEeudG528KpmmZFpXq9oV4MkLwdwLyQ48zmqyZxVKcDGsRsHPBIuPmJV/Oex+cuVTMt0nRnsw0P7mul7tL2/HeewO9Hzzs8SnbhjN9zE9q4WJfmNPUolPGJOcd60Axp1qsodY8f7L7nAsC/xldziWBP6yOxxLgoX67AFRzG9fBNPExgtFCNFGHEklhj5hJFZkgHxI9s/2KTayD2a4j31U3Byk5JfWDE1UdGIfW89rn/3p57YPHMeFDZ3l9XCbqL2xnsd2lYQWSNyyZ+b32ot0LiN8WeHyxTbKj0co7K8eQnkxrXpIH1bVoVYlmo7v5yE1z6zPWrIYxHh+MTbOzMtMqWR2qvu5nu+CfHFdQ1B3waIio7F51vmZps+l+64lHmhfl+FsXKVTbw6Hw192h2NJsHDqrZxDvanEEkOtKHOakkBsiSeGWFOPj6W2/ab6/D7nYd8nqMvUUE31RjRNT55cVW07O/HaGkRznWrr6LQamdYhNzp2FOGVUpRiYjTIWQvv+i2t/ba6Ht2EFpe6NlFhCQlF7JvvObDmPludidEn5KQnbRdrMzvMSVAC9HM2HnP0oo7WUz0YS7imBE3MudWxMufvWjPOuphczoqn2D47PHeFOcFwdn/3R91F+C+7w7Ek8Jfd4VgS+MvucCwJFku9hYN89SmYgrG1tkSJ+h0s8AdoMcN9mXNysF8XLPUWeHM+9RYURafHq6gmk1HG9eMeOqtLILdJG13oe1gMS8mCnOOh5XiIeivi7bWhv2c6VAPNUE1cOy0lGk6M4GRC1yI2hFX5mxxWaygv8sVlTv0y08U+cXStk2HXBOI+a8gXZg2Ds9IGIx0Sy9mJVjCT+2d/u7DUHg3SCmAMqHw2h8FWzH3h6RmbcNl8lgl5GAXqv+wOx5LAX3aHY0mwWOoNURfbUhglRzdZU4/JLTKZre5ZqaKZDjHBD9HmZiLNmpwspsBZU/uiAQ+JYlJCCHWtKZ9uxOspiDYrTZTchPX6DI2TEsVYIZPTegINLodlhC2arZghp6i8Q0x16yao7EH6XCpGe57GkZg2qAi9Q+5ZYPdKzz3fpzFHXJqsyDHN925PZxne7MZ9m7HGt5qvxVZOVlmSxhVgLT9duVwfx7UKcmPGj2b795z1JiJrIvK7IvK3IvIlEfl+EdkQkU+IyDOz/9fv3pPD4TguHNWM/y8A/jiE8EpMS0F9CcB7ATwVQngMwFOzfYfD8RLFUaq4dgD8AIB/DgAhhBxALiLvAPCW2WEfBPBJAO+56xln9k2RG424ySErnixiwBVBzap9ikPMvjAnGcNGRPEqqo1gonGUxArsi8Kj/cSuMCsmQLcktJybTthE1hDh+TBRZ2xl8rkTYz5TuSBbMok19VKqVrtvrjAfHA3HkXDW7eA5CNb2nWe62wQRsl1LY2aza6dcI8PWJCkzFxo5iXvYsk5cabXkge0bepjbVKP7ztey3tZuHhM7XZOQMynvrMbPx1F+2R8FcB3AfxeRz4rIf5uVbj4dQrgCALP/Tx2hL4fDcUw4ysueAXgDgN8IIbweQA/fhMkuIk+IyCURuXRju3/3DzgcjgeCo7zslwFcDiF8arb/u5i+/FdF5CwAzP6/dtCHQwhPhhAuhhAubq42DzrE4XAsAEepz/6iiDwvIq8IITyNaU32L87+vRPA+2f/f/QIfSGfRScFI/invnX2RR9RE/lkYniGkp0hy0HMKf+0f5DzM5f0uZlm0d+Z5T6ii0H+mY28oz45owyiM7SA6AOHxPie5CsH9kMT7Zfz+oAVjVDZZor+0ghKdFP3r6LhtKKiPo7mzq6z2Gg4OrPa46yxPNe0WT6MWvxcArrf1Vr8OWniT8x52b23zw4vQbBPva9yWMp+uYmqpLY6Rdc9/tCGOu7aVrSMmQ4EYsTePpFUwlF59n8F4LdEpArgWQD/AtOn9iMi8i4AXwfwk0fsy+FwHAOO9LKHED4H4OIBTW+7v8NxOBwPCgtOhAl7OmA2wk3ZPTaCjiOkyARKja004Wqv+wTE2RZjusrQSWSnjUe6QipHY2UZ6dcfQq/to++oKTcJF0z/ZER5WdOR2Z/UJvwwxZayaW3GSHMnJppM2aY0fhuxqKrc2jGqA+fu6MQjseZzOPg43QMm5A7ZElIjuodjonvHppTV9g7faz1XSizEnJuj3Dji0hrTHDFaM5p//EycasckpJedXlPHdYfxOivmXozvuHOHuKgeG+9wLAn8ZXc4lgT+sjscS4IFC04C5Sw7x5bF5VBDS2Wxr8yZV/uyzeb0Nz03+fMscpjMp3ty47NzH1WqUbaPTgoH+7wAEEg0YTjQQUb1RoxDEK6rZrLBWIhwH8PIIcOHHMfOXZpZn51DXQ/x2WmNwV4nh8WyEMe+YRyiKa8zFQ8eO2BDYvU6yLAf57jfj3TbyISb7vbj55iyBIB2K/rRfVMim33nCVGz6T5+N15As65pSr621RWqE9g0Jcn3rQ1F3Mm4O4xV9l92h2NJ4C+7w7EkECvQ8EBPJnIdwHMANgHcWNiJD8ZLYQyAj8PCx6HxzY7j5SGEkwc1LPRl3zupyKUQwkFBOks1Bh+Hj2OR43Az3uFYEvjL7nAsCY7rZX/ymM7LeCmMAfBxWPg4NO7bOI7FZ3c4HIuHm/EOx5JgoS+7iLxdRJ4Wka+IyMLUaEXkN0Xkmoh8nv62cClsETkvIn82k+P+goi8+zjGIiJ1EfkLEfmr2Th+efb3R0TkU7NxfHimX/DAISLpTN/w48c1DhH5moj8jYh8TkQuzf52HM/IA5NtX9jLLiIpgP8K4B8DeDWAnxaRVy/o9P8DwNvN345DCrsA8AshhFcBeBOAn5vNwaLHMgLw1hDC9wJ4HYC3i8ibAPwKgF+bjeM2gHc94HHcwbsxlSe/g+Maxw+GEF5HVNdxPCMPTrY9hLCQfwC+H8Cf0P77ALxvgee/AODztP80gLOz7bMAnl7UWGgMHwXww8c5FgBNAH8J4PswDd7IDrpfD/D8D88e4LcC+Dim4d3HMY6vAdg0f1vofQHQAfB3mK2l3e9xLNKMPwfgedq/PPvbceFYpbBF5AKA1wP41HGMZWY6fw5TodBPAPgqgK0Qwp2so0Xdn18H8IuIdbdOHNM4AoA/FZHPiMgTs78t+r48UNn2Rb7sByXkLCUVICIrAH4PwM+HEHaOYwwhhEkI4XWY/rK+EcCrDjrsQY5BRH4MwLUQwmf4z4sexwxvDiG8AVM38+dE5AcWcE6Le5JtvxsW+bJfBnCe9h8G8MICbGjo5QAAAXFJREFUz29xJCns+w0RqWD6ov9WCOH3j3MsABBC2MK0ms+bAKyJ7OXTLuL+vBnAj4vI1wB8CFNT/tePYRwIIbww+/8agD/A9Atw0fflnmTb74ZFvuyfBvDYbKW1CuCnAHxsgee3+BimEtjAEaWw7xUyTTr+AIAvhRB+9bjGIiInRWRttt0A8EOYLgT9GYCfWNQ4QgjvCyE8HEK4gOnz8L9CCD+76HGISEtE2ne2AfwIgM9jwfclhPAigOdF5BWzP92Rbb8/43jQCx9moeFHAXwZU//w3y3wvL8N4AqAMabfnu/C1Dd8CsAzs/83FjCOf4ipSfrXAD43+/ejix4LgO8B8NnZOD4P4N/P/v4ogL8A8BUAvwOgtsB79BYAHz+OcczO91ezf1+482we0zPyOgCXZvfmDwGs369xeASdw7Ek8Ag6h2NJ4C+7w7Ek8Jfd4VgS+MvucCwJ/GV3OJYE/rI7HEsCf9kdjiWBv+wOx5Lg/wN8Ur3WPb5xPQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 200\n",
    "plt.imshow(train_x_orig[index])\n",
    "print (\"y = \" + str(train_y[0,index]) + \". It's a \" + classes[train_y[0,index]].decode(\"utf-8\") +  \" picture.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_x's shape: (12288, 209)\n",
      "test_x's shape: (12288, 50)\n"
     ]
    }
   ],
   "source": [
    "# Reshape the training and test examples \n",
    "train_x_flatten = train_x_orig.reshape(train_x_orig.shape[0], -1).T   # The \"-1\" makes reshape flatten the remaining dimensions\n",
    "test_x_flatten = test_x_orig.reshape(test_x_orig.shape[0], -1).T\n",
    "\n",
    "# Standardize data to have feature values between 0 and 1.\n",
    "train_x = train_x_flatten/255.\n",
    "test_x = test_x_flatten/255.\n",
    "\n",
    "print (\"train_x's shape: \" + str(train_x.shape))\n",
    "print (\"test_x's shape: \" + str(test_x.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-Layer Network\n",
    "\n",
    "In order to keep things as straingtforward as possible let us begin with building a neural network with only two layers. We shall then generalize to the $L$-layer case later on.\n",
    "\n",
    "Here's an overview of the network we'll be using\n",
    "\n",
    "\n",
    "<img src=\"2layer.png\" style=\"width:650px;height:400px;\">\n",
    "\n",
    "\n",
    "### Why use ReLu?\n",
    "\n",
    "For large values of $z$ the gradients of many activation functions, such as the sigmoid or $\\tanh$ are close to zero. This can make the optimization algorithm run rather slowly. To get around this, the ReLu activation function is frequently employed, defined as\n",
    "\n",
    "$$Relu(z)=max(0,z)$$\n",
    "\n",
    "This doesn't have vanishing gradients for large $z$ and can therefore improve the efficiency of the optimization.\n",
    "\n",
    "As we still want a binary classification algorithm it is important to keep the final layer as a sigmoid so that the output is kept between 0 and 1.\n",
    "\n",
    "\n",
    "\"Researchers had great difficulty building models with many layers when using the tanh function. It is relatively flat except for a very narrow range (that range being about -2 to 2). The derivative of the function is very small unless the input is in this narrow range, and this flat derivative makes it difficult to improve the weights through gradient descent. This problem gets worse as the model has more layers. This was called the vanishing gradient problem.\n",
    "\n",
    "The ReLU function has a derivative of 0 over half it's range (the negative numbers). For positive inputs, the derivative is 1.\n",
    "\n",
    "When training on a reasonable sized batch, there will usually be some data points giving positive values to any given node. So the average derivative is rarely close to 0, which allows gradient descent to keep progressing.\" - https://www.kaggle.com/dansbecker/rectified-linear-units-relu-in-deep-learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the parameters\n",
    "\n",
    "Note that in the case of logistic regression we initialized each parameter to be zero. This was fine for a single neuron, however for a neural network this won't work as each activation neuron in a given layer will give identical values. This gives a network that is equivilent to a network with only one hidden unit in each layer of the neural network.\n",
    "\n",
    "We therefore initialise the weights to be randomly drawn from a gaussian in order to \"break the symmetry\".  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x, n_h, n_y):\n",
    "    \"\"\"\n",
    "    Argument:\n",
    "    n_x -- size of the input layer\n",
    "    n_h -- size of the hidden layer\n",
    "    n_y -- size of the output layer\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your parameters:\n",
    "                    W1 -- weight matrix of shape (n_h, n_x)\n",
    "                    b1 -- bias vector of shape (n_h, 1)\n",
    "                    W2 -- weight matrix of shape (n_y, n_h)\n",
    "                    b2 -- bias vector of shape (n_y, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "  \n",
    "    \n",
    "    \n",
    "    W1 = np.random.randn(n_h,n_x)*0.01   # Want to initialize the weights to small values to avoid regions where the activation function in the following layer flattens out. \n",
    "    b1 = np.zeros((n_h,1))\n",
    "    W2 = np.random.randn(n_y,n_h)*0.01\n",
    "    b2 = np.zeros((n_y,1))\n",
    "   \n",
    "    \n",
    "    assert(W1.shape == (n_h, n_x))\n",
    "    assert(b1.shape == (n_h, 1))\n",
    "    assert(W2.shape == (n_y, n_h))\n",
    "    assert(b2.shape == (n_y, 1))\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1 = [[-0.00272976  0.00233851  0.00425367]\n",
      " [ 0.01958286  0.02430367  0.00572942]]\n",
      "b1 = [[0.]\n",
      " [0.]]\n",
      "W2 = [[-0.00444297  0.00162377]]\n",
      "b2 = [[0.]]\n"
     ]
    }
   ],
   "source": [
    "parameters = initialize_parameters(3,2,1)\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For future convenience let's define the sigmoid and the Rectified Linear Unit (ReLU) activation functions, along with their derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    \"\"\"\n",
    "    Implements the sigmoid activation in numpy\n",
    "    \n",
    "    Arguments:\n",
    "    Z -- numpy array of any shape\n",
    "    \n",
    "    Returns:\n",
    "    A -- output of sigmoid(z), same shape as Z\n",
    "    cache -- returns Z as well, useful during backpropagation\n",
    "    \"\"\"\n",
    "    \n",
    "    A = 1/(1+np.exp(-Z))\n",
    "    cache = Z\n",
    "    \n",
    "    return A, cache\n",
    "\n",
    "def relu(Z):\n",
    "    \"\"\"\n",
    "    Implement the RELU function.\n",
    "\n",
    "    Arguments:\n",
    "    Z -- Output of the linear layer, of any shape\n",
    "\n",
    "    Returns:\n",
    "    A -- Post-activation parameter, of the same shape as Z\n",
    "    cache -- a python dictionary containing \"A\" ; stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    A = np.maximum(0,Z)\n",
    "    \n",
    "    assert(A.shape == Z.shape)\n",
    "    \n",
    "    cache = Z \n",
    "    return A, cache\n",
    "\n",
    "\n",
    "def relu_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for a single RELU unit.\n",
    "\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient, of any shape\n",
    "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "\n",
    "    Returns:\n",
    "    dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = cache\n",
    "    dZ = np.array(dA, copy=True) # just converting dz to a correct object.\n",
    "    \n",
    "    # When z <= 0, you should set dz to 0 as well. \n",
    "    dZ[Z <= 0] = 0\n",
    "    \n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ\n",
    "\n",
    "def sigmoid_backward(dA, cache):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for a single SIGMOID unit.\n",
    "\n",
    "    Arguments:\n",
    "    dA -- post-activation gradient, of any shape\n",
    "    cache -- 'Z' where we store for computing backward propagation efficiently\n",
    "\n",
    "    Returns:\n",
    "    dZ -- Gradient of the cost with respect to Z\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = cache\n",
    "    \n",
    "    s = 1/(1+np.exp(-Z))\n",
    "    dZ = dA * s * (1-s)\n",
    "    \n",
    "    assert (dZ.shape == Z.shape)\n",
    "    \n",
    "    return dZ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The linear part of the forward propagation algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "    \"\"\"\n",
    "    Implement the linear part of a layer's forward propagation.\n",
    "\n",
    "    Arguments:\n",
    "    A -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "\n",
    "    Returns:\n",
    "    Z -- the input of the activation function, also called pre-activation parameter \n",
    "    cache -- a python tuple containing \"A\", \"W\" and \"b\" ; stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    Z = np.dot(W,A)+b\n",
    "    \n",
    "    assert(Z.shape == (W.shape[0], A.shape[1]))\n",
    "    cache = (A, W, b)\n",
    "    \n",
    "    return Z, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_forward(A_prev, W, b, activation):\n",
    "    \"\"\"\n",
    "    Implement the forward propagation for the LINEAR->ACTIVATION layer\n",
    "\n",
    "    Arguments:\n",
    "    A_prev -- activations from previous layer (or input data): (size of previous layer, number of examples)\n",
    "    W -- weights matrix: numpy array of shape (size of current layer, size of previous layer)\n",
    "    b -- bias vector, numpy array of shape (size of the current layer, 1)\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "\n",
    "    Returns:\n",
    "    A -- the output of the activation function, also called the post-activation value \n",
    "    cache -- a python tuple containing \"linear_cache\" and \"activation_cache\";\n",
    "             stored for computing the backward pass efficiently\n",
    "    \"\"\"\n",
    "    \n",
    "    if activation == \"sigmoid\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "    \n",
    "    elif activation == \"relu\":\n",
    "        # Inputs: \"A_prev, W, b\". Outputs: \"A, activation_cache\".\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = relu(Z)\n",
    "    \n",
    "    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n",
    "    cache = (linear_cache, activation_cache)\n",
    "\n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the cost function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(AL, Y):\n",
    "    \"\"\"\n",
    "    Implement the cost function defined by equation (7).\n",
    "\n",
    "    Arguments:\n",
    "    AL -- probability vector corresponding to your label predictions, shape (1, number of examples)\n",
    "    Y -- true \"label\" vector (for example: containing 0 if non-cat, 1 if cat), shape (1, number of examples)\n",
    "\n",
    "    Returns:\n",
    "    cost -- cross-entropy cost\n",
    "    \"\"\"\n",
    "    \n",
    "    m = Y.shape[1]\n",
    "\n",
    "    # Compute loss from aL and y\n",
    "    cost = -np.sum(np.multiply(np.log(AL),Y)+np.multiply(np.log(1-AL),1-Y))/m \n",
    "    \n",
    "    \n",
    "    cost = np.squeeze(cost)      # To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).\n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the derivatives for backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dZ, cache):\n",
    "    \"\"\"\n",
    "    Implement the linear portion of backward propagation for a single layer (layer l)\n",
    "\n",
    "    Arguments:\n",
    "    dZ -- Gradient of the cost with respect to the linear output (of current layer l)\n",
    "    cache -- tuple of values (A_prev, W, b) coming from the forward propagation in the current layer\n",
    "\n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "\n",
    "    ### START CODE HERE ### (≈ 3 lines of code)\n",
    "    dW = np.dot(dZ,A_prev.T)/m\n",
    "    db = np.sum(dZ, axis=1, keepdims=True)/m\n",
    "    dA_prev = np.dot(W.T,dZ)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    assert (dA_prev.shape == A_prev.shape)\n",
    "    assert (dW.shape == W.shape)\n",
    "    assert (db.shape == b.shape)\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_activation_backward(dA, cache, activation):\n",
    "    \"\"\"\n",
    "    Implement the backward propagation for the LINEAR->ACTIVATION layer.\n",
    "    \n",
    "    Arguments:\n",
    "    dA -- post-activation gradient for current layer l \n",
    "    cache -- tuple of values (linear_cache, activation_cache) we store for computing backward propagation efficiently\n",
    "    activation -- the activation to be used in this layer, stored as a text string: \"sigmoid\" or \"relu\"\n",
    "    \n",
    "    Returns:\n",
    "    dA_prev -- Gradient of the cost with respect to the activation (of the previous layer l-1), same shape as A_prev\n",
    "    dW -- Gradient of the cost with respect to W (current layer l), same shape as W\n",
    "    db -- Gradient of the cost with respect to b (current layer l), same shape as b\n",
    "    \"\"\"\n",
    "    linear_cache, activation_cache = cache\n",
    "    \n",
    "    if activation == \"relu\":\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "    elif activation == \"sigmoid\":\n",
    "        ### START CODE HERE ### (≈ 2 lines of code)\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "        ### END CODE HERE ###\n",
    "    \n",
    "    return dA_prev, dW, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    \"\"\"\n",
    "    Update parameters using gradient descent\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters \n",
    "    grads -- python dictionary containing your gradients, output of L_model_backward\n",
    "    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your updated parameters \n",
    "                  parameters[\"W\" + str(l)] = ... \n",
    "                  parameters[\"b\" + str(l)] = ...\n",
    "    \"\"\"\n",
    "    \n",
    "    L = len(parameters) // 2 # number of layers in the neural network\n",
    "\n",
    "    # Update rule for each parameter. Use a for loop.\n",
    "    for l in range(L):\n",
    "        parameters[\"W\" + str(l+1)] = parameters[\"W\" + str(l+1)]-learning_rate*grads[\"dW\" + str(l + 1)]\n",
    "        parameters[\"b\" + str(l+1)] = parameters[\"b\" + str(l+1)]-learning_rate*grads[\"db\" + str(l + 1)]\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect everything together into a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_layer_model(X, Y, layers_dims, learning_rate = 0.0075, num_iterations = 3000, print_cost=False):\n",
    "    \"\"\"\n",
    "    Implements a two-layer neural network: LINEAR->RELU->LINEAR->SIGMOID.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- input data, of shape (n_x, number of examples)\n",
    "    Y -- true \"label\" vector (containing 1 if cat, 0 if non-cat), of shape (1, number of examples)\n",
    "    layers_dims -- dimensions of the layers (n_x, n_h, n_y)\n",
    "    num_iterations -- number of iterations of the optimization loop\n",
    "    learning_rate -- learning rate of the gradient descent update rule\n",
    "    print_cost -- If set to True, this will print the cost every 100 iterations \n",
    "    \n",
    "    Returns:\n",
    "    parameters -- a dictionary containing W1, W2, b1, and b2\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(1)\n",
    "    grads = {}\n",
    "    costs = []                              # to keep track of the cost\n",
    "    m = X.shape[1]                           # number of examples\n",
    "    (n_x, n_h, n_y) = layers_dims\n",
    "    \n",
    "    # Initialize parameters dictionary, by calling one of the functions you'd previously implemented\n",
    "    parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "    \n",
    "    # Get W1, b1, W2 and b2 from the dictionary parameters.\n",
    "    W1 = parameters[\"W1\"]\n",
    "    b1 = parameters[\"b1\"]\n",
    "    W2 = parameters[\"W2\"]\n",
    "    b2 = parameters[\"b2\"]\n",
    "    \n",
    "    # Loop (gradient descent)\n",
    "\n",
    "    for i in range(0, num_iterations):\n",
    "\n",
    "        # Forward propagation: LINEAR -> RELU -> LINEAR -> SIGMOID. Inputs: \"X, W1, b1, W2, b2\". Output: \"A1, cache1, A2, cache2\".\n",
    "        A1, cache1 = linear_activation_forward(X, W1, b1, \"relu\")\n",
    "        A2, cache2 = linear_activation_forward(A1, W2, b2, \"sigmoid\")\n",
    "       \n",
    "        \n",
    "        # Compute cost\n",
    "        cost = compute_cost(A2, Y)\n",
    "\n",
    "        \n",
    "        # Initializing backward propagation\n",
    "        dA2 = - (np.divide(Y, A2) - np.divide(1 - Y, 1 - A2))\n",
    "        \n",
    "        # Backward propagation. Inputs: \"dA2, cache2, cache1\". Outputs: \"dA1, dW2, db2; also dA0 (not used), dW1, db1\".\n",
    "        dA1, dW2, db2 = linear_activation_backward(dA2, cache2, \"sigmoid\")\n",
    "        dA0, dW1, db1 = linear_activation_backward(dA1, cache1, \"relu\")\n",
    "        \n",
    "        \n",
    "        # Set grads['dWl'] to dW1, grads['db1'] to db1, grads['dW2'] to dW2, grads['db2'] to db2\n",
    "        grads['dW1'] = dW1\n",
    "        grads['db1'] = db1\n",
    "        grads['dW2'] = dW2\n",
    "        grads['db2'] = db2\n",
    "        \n",
    "        # Update parameters.\n",
    "        parameters = update_parameters(parameters, grads, learning_rate)\n",
    "        \n",
    "\n",
    "        # Retrieve W1, b1, W2, b2 from parameters\n",
    "        W1 = parameters[\"W1\"]\n",
    "        b1 = parameters[\"b1\"]\n",
    "        W2 = parameters[\"W2\"]\n",
    "        b2 = parameters[\"b2\"]\n",
    "        \n",
    "        # Print the cost every 100 training example\n",
    "        if print_cost and i % 100 == 0:\n",
    "            print(\"Cost after iteration {}: {}\".format(i, np.squeeze(cost)))\n",
    "        if print_cost and i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "       \n",
    "    # plot the cost\n",
    "\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per hundreds)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CONSTANTS DEFINING THE MODEL - One hidden layer ####\n",
    "n_x = 12288     # num_px * num_px * 3\n",
    "n_h = 7 # number of activation units \n",
    "n_y = 1 # output units \n",
    "layers_dims = (n_x, n_h, n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.6930497356599891\n",
      "Cost after iteration 100: 0.6464320953428849\n",
      "Cost after iteration 200: 0.6325140647912677\n",
      "Cost after iteration 300: 0.6015024920354665\n",
      "Cost after iteration 400: 0.5601966311605748\n",
      "Cost after iteration 500: 0.515830477276473\n",
      "Cost after iteration 600: 0.4754901313943325\n",
      "Cost after iteration 700: 0.4339163151225749\n",
      "Cost after iteration 800: 0.40079775362038866\n",
      "Cost after iteration 900: 0.3580705011323798\n",
      "Cost after iteration 1000: 0.3394281538366414\n",
      "Cost after iteration 1100: 0.3052753636196265\n",
      "Cost after iteration 1200: 0.2749137728213017\n",
      "Cost after iteration 1300: 0.24681768210614827\n",
      "Cost after iteration 1400: 0.198507350374661\n",
      "Cost after iteration 1500: 0.17448318112556616\n",
      "Cost after iteration 1600: 0.17080762978096295\n",
      "Cost after iteration 1700: 0.1130652456216473\n",
      "Cost after iteration 1800: 0.09629426845937158\n",
      "Cost after iteration 1900: 0.0834261795972687\n",
      "Cost after iteration 2000: 0.07439078704319091\n",
      "Cost after iteration 2100: 0.06630748132267937\n",
      "Cost after iteration 2200: 0.05919329501038175\n",
      "Cost after iteration 2300: 0.05336140348560559\n",
      "Cost after iteration 2400: 0.04855478562877021\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "parameters_two_layer = two_layer_model(train_x, train_y, layers_dims = (n_x, n_h, n_y),learning_rate = 0.0075, num_iterations = 2500, print_cost=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L_model_forward(X, parameters):\n",
    "    \"\"\"\n",
    "    Implement forward propagation for the [LINEAR->RELU]*(L-1)->LINEAR->SIGMOID computation\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data, numpy array of shape (input size, number of examples)\n",
    "    parameters -- output of initialize_parameters_deep()\n",
    "    \n",
    "    Returns:\n",
    "    AL -- last post-activation value\n",
    "    caches -- list of caches containing:\n",
    "                every cache of linear_activation_forward() (there are L-1 of them, indexed from 0 to L-1)\n",
    "    \"\"\"\n",
    "\n",
    "    caches = []\n",
    "    A = X\n",
    "    L = len(parameters) // 2                  # number of layers in the neural network\n",
    "    \n",
    "    # Implement [LINEAR -> RELU]*(L-1). Add \"cache\" to the \"caches\" list.\n",
    "    for l in range(1, L):\n",
    "        A_prev = A \n",
    "        A, cache = linear_activation_forward(A_prev, parameters['W' + str(l)], parameters['b' + str(l)], 'relu')\n",
    "        caches.append(cache)\n",
    "    \n",
    "    # Implement LINEAR -> SIGMOID. Add \"cache\" to the \"caches\" list.\n",
    "    AL, cache = linear_activation_forward(A, parameters['W' + str(L)], parameters['b' + str(L)], 'sigmoid')\n",
    "    caches.append(cache)\n",
    "    \n",
    "    assert(AL.shape == (1,X.shape[1]))\n",
    "            \n",
    "    return AL, caches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X, y, parameters):\n",
    "    \"\"\"\n",
    "    This function is used to predict the results of a  L-layer neural network.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- data set of examples you would like to label\n",
    "    parameters -- parameters of the trained model\n",
    "    \n",
    "    Returns:\n",
    "    p -- predictions for the given dataset X\n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    n = len(parameters) // 2 # number of layers in the neural network\n",
    "    p = np.zeros((1,m))\n",
    "    \n",
    "    # Forward propagation\n",
    "    probas, caches = L_model_forward(X, parameters)\n",
    "\n",
    "    \n",
    "    # convert probas to 0/1 predictions\n",
    "    for i in range(0, probas.shape[1]):\n",
    "        if probas[0,i] > 0.5:\n",
    "            p[0,i] = 1\n",
    "        else:\n",
    "            p[0,i] = 0\n",
    "    \n",
    "    #print results\n",
    "    #print (\"predictions: \" + str(p))\n",
    "    #print (\"true labels: \" + str(y))\n",
    "    print(\"Accuracy: \"  + str(np.sum((p == y)/m)))\n",
    "        \n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9999999999999998\n",
      "Accuracy: 0.72\n"
     ]
    }
   ],
   "source": [
    "predictions_train = predict(train_x, train_y, parameters_two_layer) \n",
    "\n",
    "predictions_test = predict(test_x, test_y, parameters_two_layer) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'skimage' has no attribute 'io'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-a932053da411>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# We preprocess the image to fit your algorithm.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"images/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmy_image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_gray\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m255.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mmy_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mskimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnum_px\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_px\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'skimage' has no attribute 'io'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "my_image = \"Multiple_layers_cat.jpg\"\n",
    "my_label_y = [0]                           # change this to the name of your image file \n",
    "\n",
    "\n",
    "# We preprocess the image to fit your algorithm.\n",
    "fname = \"images/\" + my_image\n",
    "image = np.array(skimage.io.imread(fname, as_gray=False))\n",
    "image = image/255.\n",
    "my_image = skimage.transform.resize(image, (num_px,num_px))\n",
    "#my_image = my_image.reshape(my_image.shape[0],-1).T  \n",
    "my_image = my_image.reshape(num_px*num_px*3,1) \n",
    "\n",
    "#my_image = skimage.transform.resize(my_image, (num_px*num_px*3,1))\n",
    "\n",
    "my_predicted_image = predict(my_image, my_label_y, parameters_two_layer)\n",
    "\n",
    "#my_predicted_image = predict(d[\"w\"], d[\"b\"], my_image)\n",
    "\n",
    "plt.imshow(image)\n",
    "print(\"y = \" + str(np.squeeze(my_predicted_image)) + \", your algorithm predicts a \\\"\" + classes[int(np.squeeze(my_predicted_image)),].decode(\"utf-8\") +  \"\\\" picture.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_validate_lengths' from 'numpy.lib.arraypad' (/anaconda3/lib/python3.7/site-packages/numpy/lib/arraypad.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-388294a8b02f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mskimage\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmy_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"lemur.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmy_label_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m                           \u001b[0;31m# change this to the name of your image file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/skimage/io/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcollection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_io\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_image_stack\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/skimage/io/_io.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanage_plugins\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrgb2gray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexposure\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_low_contrast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/skimage/color/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m from .colorconv import (convert_colorspace,\n\u001b[0m\u001b[1;32m      2\u001b[0m                         \u001b[0mguess_spatial_dimensions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                         \u001b[0mrgba2rgb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                         \u001b[0mrgb2hsv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                         \u001b[0mhsv2rgb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/skimage/color/colorconv.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype_limits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/skimage/util/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mapply_parallel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapply_parallel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0marraycrop\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcrop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_regular_grid\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregular_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregular_seeds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munique_rows\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/skimage/util/arraycrop.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marraypad\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_validate_lengths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '_validate_lengths' from 'numpy.lib.arraypad' (/anaconda3/lib/python3.7/site-packages/numpy/lib/arraypad.py)"
     ]
    }
   ],
   "source": [
    "my_image = \"lemur.jpg\"\n",
    "my_label_y = [0]                           # change this to the name of your image file \n",
    "\n",
    "\n",
    "# We preprocess the image to fit your algorithm.\n",
    "fname = \"images/\" + my_image\n",
    "image = np.array(skimage.io.imread(fname, as_gray=False))\n",
    "image = image/255.\n",
    "my_image = skimage.transform.resize(image, (num_px,num_px))\n",
    "#my_image = my_image.reshape(my_image.shape[0],-1).T  \n",
    "my_image = my_image.reshape(num_px*num_px*3,1) \n",
    "\n",
    "#my_image = skimage.transform.resize(my_image, (num_px*num_px*3,1))\n",
    "\n",
    "my_predicted_image = predict(my_image, my_label_y, parameters_two_layer)\n",
    "\n",
    "#my_predicted_image = predict(d[\"w\"], d[\"b\"], my_image)\n",
    "\n",
    "plt.imshow(image)\n",
    "print(\"y = \" + str(np.squeeze(my_predicted_image)) + \", your algorithm predicts a \\\"\" + classes[int(np.squeeze(my_predicted_image)),].decode(\"utf-8\") +  \"\\\" picture.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
